{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "268c7200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple MLP implementation that learns multiplication of two numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "5c72613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "77f20f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class. Prepare the dataset, normalize the inputs and targets, split into training and testing subsets\n",
    "\n",
    "class MultiDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        # Normalize the dataset using Z norm\n",
    "        self.x = (x - np.mean(x)) / np.std(x) \n",
    "        self.y = (y - np.mean(y)) / np.std(y) \n",
    "        \n",
    "        # Alternatively can normalize dividing input and target by their respective max values\n",
    "        #self.x = x / np.max(x) \n",
    "        #self.y = y / np.max(y)\n",
    "        \n",
    "        self.x = self.x.astype('float32')\n",
    "        self.y = self.y.reshape(len(y), 1)\n",
    "        self.y = self.y.astype('float32')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.x[idx], self.y[idx]]\n",
    "    \n",
    "    def get_splits(self, n_test = 0.33):\n",
    "        test_size = round(n_test * len(self.x))\n",
    "        train_size = len(self.x) - test_size\n",
    "        \n",
    "        return torch.utils.data.random_split(self, [train_size, test_size]) \n",
    "    \n",
    "    def prepare_dataset(self):\n",
    "        train, test = self.get_splits()\n",
    "        train_dl = torch.utils.data.DataLoader(train, batch_size=4, shuffle=True) # Test with larger batch numbers\n",
    "        test_dl = torch.utils.data.DataLoader(train, batch_size=32, shuffle=False)\n",
    "        \n",
    "        return train_dl, test_dl\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dab444ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron model with 3 hidden layers\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()        \n",
    "        self.hidden1 = torch.nn.Sequential(torch.nn.Linear(n_inputs, 200), torch.nn.Sigmoid())\n",
    "        self.hidden2 = torch.nn.Sequential(torch.nn.Linear(200, 100), torch.nn.Sigmoid())        \n",
    "        self.hidden3 = torch.nn.Sequential(torch.nn.Linear(100, 20), torch.nn.Sigmoid())\n",
    "        self.output = torch.nn.Sequential(torch.nn.Linear(20,1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.hidden1(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = self.hidden3(X)\n",
    "        X = self.output(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "8844840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "def train_model(train_dl, model, num_of_epochs=30):    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # Adam optimizer performs better compared to SGD\n",
    "    \n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=100)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.1) # SGD optimizer\n",
    "    error = [] # Collect errors for plotting\n",
    "    lrs = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, num_of_epochs+1): # Train for the specified number of epochs\n",
    "        for i, (inputs, targets) in enumerate(train_dl):        \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(inputs)\n",
    "            loss = criterion(y_hat, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        error.append(np.mean(loss.item())) \n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        #scheduler.step()\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == num_of_epochs-1: # Print loss at every 5th epoch\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        \n",
    "    plt.plot(error) \n",
    "    #plt.plot(lrs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "a4ba6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        y_hat = model(inputs)\n",
    "        y_hat = y_hat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        \n",
    "        predictions.append(y_hat)\n",
    "        actuals.append(actual)\n",
    "        \n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "c6bcf7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the output\n",
    "\n",
    "def predict(row, model):\n",
    "    row = torch.Tensor([row]) # Convert row to Torch tensor format\n",
    "    row_norm = (row - np.mean(x)) / np.std(x) # normalise the input using Z norm\n",
    "    y_hat = model(row_norm)\n",
    "    y_hat = y_hat.detach().numpy()\n",
    "    y_hat_norm = np.std(y) * y_hat + np.mean(y) # De-normalise the output \n",
    "    \n",
    "    return y_hat_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "df580876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model's linear layer weights\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "bd02d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset containing two numbers as input and multiplication result as output\n",
    "\n",
    "x = []\n",
    "y = np.zeros(5000) # sample size\n",
    "\n",
    "for d in range(len(y)):\n",
    "    x.append([np.random.randint(1,10), np.random.randint(1,10)]) # Trained on ranges between 0 to 10. \n",
    "\n",
    "    y[d] = x[d][0] * x[d][1] \n",
    "\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "23c5d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [2 5], output: 10.0\n"
     ]
    }
   ],
   "source": [
    "# Review the dataset\n",
    "\n",
    "print(f\"input: {x[1]}, output: {y[1]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "acc9c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiDataset(x, y) # Create ataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ed2fd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = dataset.prepare_dataset() # Prepare dataset with train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "84b28d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838 105\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl), len(test_dl)) # Check the length of training and testing batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "25671ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLP model with inputs of length 2. Initialize model weights\n",
    "model = MLP(2) \n",
    "init_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e37d795a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0007800034945830703\n",
      "Epoch 10, Loss: 0.08529987931251526\n",
      "Epoch 15, Loss: 0.05285022780299187\n",
      "Epoch 20, Loss: 4.214355158183025e-06\n",
      "Epoch 25, Loss: 0.003148031886667013\n",
      "Epoch 30, Loss: 0.0003848882915917784\n",
      "Epoch 34, Loss: 9.230915020452812e-05\n",
      "Epoch 35, Loss: 4.068821453984128e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model for 35 epochs\n",
    "train_model(train_dl, model, 35) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e4f23e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.000, RMSE: 0.007\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using mean square error and root mean square error\n",
    "mse = evaluate_model(test_dl, model) \n",
    "print(\"MSE: %.3f, RMSE: %.3f\" % (mse, sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "effe82d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Input: (1, 8). Predicted result: 7.919, actual: 8\n",
      "2 - Input: (9, 5). Predicted result: 45.147, actual: 45\n",
      "3 - Input: (7, 4). Predicted result: 28.124, actual: 28\n",
      "4 - Input: (3, 2). Predicted result: 6.008, actual: 6\n",
      "5 - Input: (5, 1). Predicted result: 5.170, actual: 5\n",
      "6 - Input: (3, 1). Predicted result: 3.129, actual: 3\n",
      "7 - Input: (9, 8). Predicted result: 72.260, actual: 72\n",
      "8 - Input: (3, 4). Predicted result: 11.929, actual: 12\n",
      "9 - Input: (9, 6). Predicted result: 54.085, actual: 54\n",
      "10 - Input: (1, 2). Predicted result: 1.930, actual: 2\n"
     ]
    }
   ],
   "source": [
    "# Test learned multiplication with some random samples \n",
    "for g in range(1,11):\n",
    "    sample = np.array([np.random.randint(1,10), np.random.randint(1,10)])\n",
    "    predicted = predict(sample, model)\n",
    "    actual = sample[0] * sample[1]\n",
    "    print(f'{g} - Input: ({sample[0]}, {sample[1]}). Predicted result: {predicted.item():.3f}, actual: {actual}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ac79a2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.566 \n"
     ]
    }
   ],
   "source": [
    "# Manually test a sample of numbers between 1-10\n",
    "print(\"%.3f \" % predict(np.array([20,15]), model).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "46b87484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden1): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=200, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (hidden2): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (hidden3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=20, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
